##################################################################################
# Soft Actor-Critic (SAC)
##################################################################################

agent_type: 'sac'

seed: ${seed}
num_train_envs: ${env.num_train_envs}
max_episode_steps: ${env.max_episode_steps}
normalize_observation: false

actor_block_type: 'mlp'
actor_num_blocks: 1
actor_hidden_dim: 256
actor_learning_rate: 3e-4
actor_weight_decay: 0.0

critic_block_type: 'mlp'
critic_num_blocks: 1
critic_hidden_dim: 256
critic_learning_rate: 3e-4
critic_weight_decay: 0.0
critic_use_cdq: true

temp_target_entropy: null # entropy_coef * action_dim
temp_target_entropy_coef: -1.0 
temp_initial_value: 1.0
temp_learning_rate: 3e-4
temp_weight_decay: 0.0

target_tau: 0.005
gamma: ${gamma}
n_step: ${n_step}

mixed_precision: false
