##################################################################################
# Soft Actor-Critic with Simba architecture
##################################################################################

agent_type: 'sac'

seed: ${seed}
num_train_envs: ${env.num_train_envs}
max_episode_steps: ${env.max_episode_steps}
normalize_observation: true

actor_block_type: 'residual'
actor_num_blocks: 1
actor_hidden_dim: 128
actor_learning_rate: 1e-4
actor_weight_decay: 1e-2

critic_block_type: 'residual'
critic_num_blocks: 2
critic_hidden_dim: 512
critic_learning_rate: 1e-4
critic_weight_decay: 1e-2
critic_use_cdq: ${env.episodic}

temp_target_entropy: null # entropy_coef * action_dim
temp_target_entropy_coef: -0.5 
temp_initial_value: 0.01
temp_learning_rate: 1e-4
temp_weight_decay: 0.0

target_tau: 0.005
gamma: ${gamma}
n_step: ${n_step}

mixed_precision: false
